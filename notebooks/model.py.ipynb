{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../src')\n",
    "import config\n",
    "import util\n",
    "\n",
    "import data_processing as dp\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "torch.manual_seed(config.SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(config.SEED)\n",
    "torch.multiprocessing.freeze_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_filter_list=['Atelectasis']\n",
    "position_filter_list=['PA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Atelectasis',\n",
       " 'Cardiomegaly',\n",
       " 'Consolidation',\n",
       " 'Edema',\n",
       " 'Effusion',\n",
       " 'Emphysema',\n",
       " 'Fibrosis',\n",
       " 'Hernia',\n",
       " 'Infiltration',\n",
       " 'Mass',\n",
       " 'Nodule',\n",
       " 'Pleural_Thickening',\n",
       " 'Pneumonia',\n",
       " 'Pneumothorax']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data, labels   = dp.load_data()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if disease_filter_list:\n",
    "    labels = disease_filter_list\n",
    "    #df_data = df_data[df_data['Finding Labels'].isin(disease_filter_list)]\n",
    "          \n",
    "if position_filter_list:\n",
    "    df_data = df_data[df_data['View Position'].isin(position_filter_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>Follow Up</th>\n",
       "      <th>View Position</th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Image_path</th>\n",
       "      <th>Finding Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>PA</td>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>..\\data\\raw\\images\\00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>..\\data\\raw\\images\\00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>PA</td>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>..\\data\\raw\\images\\00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>PA</td>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>..\\data\\raw\\images\\00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>PA</td>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>..\\data\\raw\\images\\00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID  Patient Age Patient Gender  Follow Up View Position  \\\n",
       "0           1           58              M          0            PA   \n",
       "1           1           58              M          1            PA   \n",
       "2           1           58              M          2            PA   \n",
       "3           2           81              M          0            PA   \n",
       "4           3           81              F          0            PA   \n",
       "\n",
       "        Image Index                           Image_path  \\\n",
       "0  00000001_000.png  ..\\data\\raw\\images\\00000001_000.png   \n",
       "1  00000001_001.png  ..\\data\\raw\\images\\00000001_001.png   \n",
       "2  00000001_002.png  ..\\data\\raw\\images\\00000001_002.png   \n",
       "3  00000002_000.png  ..\\data\\raw\\images\\00000002_000.png   \n",
       "4  00000003_000.png  ..\\data\\raw\\images\\00000003_000.png   \n",
       "\n",
       "           Finding Labels  \n",
       "0            Cardiomegaly  \n",
       "1  Cardiomegaly|Emphysema  \n",
       "2   Cardiomegaly|Effusion  \n",
       "3              No Finding  \n",
       "4                  Hernia  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Atelectasis']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data, dict_labels = dp.multi_hot_label(df_data, labels)\n",
    "df_train, df_test    = dp.make_train_test_split(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Atelectasis'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44971"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_val   = dp.train_test_split(df_train) \n",
    "df_train, df_test, df_val = df_train.reset_index(drop=True), df_test.reset_index(drop=True), df_val.reset_index(drop=True)\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11096"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11243"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NihDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image  = Image.open(self.dataframe.loc[idx, 'Image_path']).convert('L')  # via .getband(), some images are know to have 4 channels. Here we convert them to 1-channel grayscale.\n",
    "        target = self.dataframe.loc[idx, 'Labels']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataframe, transform=None, batch_size=32, shuffle=True, num_workers=4):\n",
    "    '''\n",
    "    Data Loader with batch loading and transform.\n",
    "    '''\n",
    "    image_data = NihDataset(dataframe, transform=transform)\n",
    "    pin = device=='cpu'\n",
    "    num_workers=num_workers*int(device!='cpu')\n",
    "    loader = torch.utils.data.DataLoader(image_data, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, labels):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5)  # stride=1, padding=0\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(3, 8, 5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(8, 16, 5)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 10 * 10, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)  # 14 classes\n",
    "        \n",
    "        self.out = nn.Linear(64, len(labels))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))  # size: (batch_size*)3channels*110*110\n",
    "        x = self.pool2(F.relu(self.conv2(x)))  # size: (batch_size*)8channels*53*53\n",
    "        x = self.pool3(F.relu(self.conv3(x)))  # size: (batch_size*)8channels*53*53\n",
    "        x = x.view(-1, 16 * 10 * 10)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        out = torch.sigmoid(self.out(x))\n",
    "        #x = F.softmax(self.fc3(x))                # change to softmax if multiclass\n",
    "        return out\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, labels):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5)  # stride=1, padding=0\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(3, 8, 5)\n",
    "        self.fc1 = nn.Linear(8 * 25 * 25, 60)\n",
    "        self.fc2 = nn.Linear(60, 20)\n",
    "        self.fc3 = nn.Linear(20, len(labels))  # 2 classes\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # size: (batch_size*)3channels*110*110\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # size: (batch_size*)8channels*53*53\n",
    "        x = x.view(-1, 8 * 25 * 25)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = torch.sigmoid(self.fc3(x))  # change to softmax if multiclass\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_category_loss_fn(outputs, targets):\n",
    "    \n",
    "    tl = []\n",
    "    for o,t in zip(outputs.T, targets.T):\n",
    "        tl.append(nn.BCELoss()(o, t))\n",
    "        \n",
    "    return sum(tl) / len(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleNet(dict_labels).to(device)\n",
    "#model = Net(dict_labels).to(device)\n",
    "len(dict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()  # change to CrossEntropyLoss if  multiclass\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs=config.NUM_EPOCHS\n",
    "num_epochs=3\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((112,112)),\n",
    "        transforms.RandomHorizontalFlip(),  # data augmentation\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((128,128)),\n",
    "        transforms.CenterCrop(112),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = load_data(df_train, transform=data_transforms['train'], shuffle=False, batch_size=config.TRAIN_BATCH_SIZE, num_workers=0)\n",
    "val_data_loader   = load_data(df_val  , transform=data_transforms['test'] , shuffle=False, batch_size=config.VAL_BATCH_SIZE  , num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1600, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_data_loader, 0):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.type(torch.FloatTensor).to(device)\n",
    "            \n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    loss = multi_category_loss_fn(outputs, labels)\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    print(\".\", end =\"\")\n",
    "    if i % 10 == 9:    # print every 10 mini-batches\n",
    "        print(f'\\nEpoch: {epoch + 1:>2} , Bacth: {i + 1:>3} , loss: {running_loss / (i+1)}')\n",
    "        #print(f\"Average time per batch: {(time.time()-start_time)/(i+1)} secs\")\n",
    "        #running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    Y_prob, Y_pred, Y_true = [], [], []\n",
    "    for idx, (images, labels) in enumerate(val_data_loader):\n",
    "        probs = model(images.to(device))\n",
    "        labels = labels.type(torch.FloatTensor).to(device)\n",
    "        val_loss += multi_category_loss_fn(probs, labels)\n",
    "        predicted = probs > 0.5\n",
    "                \n",
    "        probs = probs.cpu().detach().numpy().astype(float)\n",
    "        predicted = predicted.cpu().detach().numpy().astype(float)\n",
    "        labels = labels.cpu().detach().numpy().astype(float)\n",
    "        Y_prob.append(probs)\n",
    "        Y_pred.append(predicted)\n",
    "        Y_true.append(labels)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch              : 2/3\n",
      "Training Loss      : 0.7397649884223938\n",
      "Validation Loss    : 0.29458072781562805\n",
      "Validation Accuracy: 0.92\n",
      "Validation ROC     : 0.3383152173913043\n"
     ]
    }
   ],
   "source": [
    "Y_prob = np.concatenate(Y_prob, axis=0)\n",
    "Y_pred = np.concatenate(Y_pred, axis=0)\n",
    "Y_true = np.concatenate(Y_true, axis=0)\n",
    "print()\n",
    "        \n",
    "train_losses.append(running_loss/len(train_data_loader))\n",
    "val_losses.append(val_loss/len(val_data_loader))\n",
    "acc = accuracy_score(Y_true, Y_pred)\n",
    "roc = roc_auc_score(Y_true, Y_prob)\n",
    "        \n",
    "print(f\"Epoch              : {epoch+1}/{num_epochs}\")\n",
    "print(f\"Training Loss      : {train_losses[-1]}\")\n",
    "print(f\"Validation Loss    : {val_losses[-1]}\")\n",
    "print(f\"Validation Accuracy: {acc}\")\n",
    "print(f\"Validation ROC     : {roc}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
