{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "historic-sender",
   "metadata": {},
   "source": [
    "# Starter notebook for NIH Chest Xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-specific setting\n",
    "PROJECT = 'mcsds-dlh'  # CHANGE: billing project name (since the dataset is user-to-pay)\n",
    "DATA_FOLDER = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-albert",
   "metadata": {},
   "source": [
    "## Copy data from GCS (do only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images from GCS. Takes a few minutes.\n",
    "# Note: you may have trouble running these commands locally, with error \"ServiceException: 401 Requester pays bucket access requires authentication.\"\n",
    "# This is due to:\n",
    "# 1. Billing was not setup correctly on Google Cloud.\n",
    "# 2. Command shell needs admin privilege.\n",
    "# Better alternative is to copy the data to another bucket and download from there, or from Kaggle.\n",
    "\n",
    "# Images\n",
    "# https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest#gcp_data_access\n",
    "#!gsutil -u {PROJECT} -m -q cp -r gs://gcs-public-data--healthcare-nih-chest-xray/png/*.png {DATA_FOLDER}\n",
    "\n",
    "# Download addition labels\n",
    "# https://pubs.rsna.org/doi/10.1148/radiol.2019191293\n",
    "#!gsutil -u {PROJECT} -m -q cp -r gs://gcs-public-data--healthcare-nih-chest-xray-labels/* {DATA_FOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-mother",
   "metadata": {},
   "source": [
    "# Code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from functions import NihDataset, load_data, train_model, eval_model\n",
    "%matplotlib inline\n",
    "\n",
    "# check if CUDA is available (GPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataset\n",
    "# load train test split\n",
    "with open('train_val_list.txt') as f: \n",
    "    train_val_list = [x.strip() for x in f.readlines()]\n",
    "with open('test_list.txt') as f:\n",
    "    test_list = [x.strip() for x in f.readlines()]\n",
    "\n",
    "# load labels\n",
    "df_labels = pd.read_csv('Data_Entry_2017_v2020.csv')\n",
    "print(f\"Number of images: {len(df_labels)}\")\n",
    "# split the finding (disease) labels, to a list\n",
    "df_labels['targets'] = df_labels['Finding Labels'].str.split(\"|\", expand = False)\n",
    "# look at available labels\n",
    "labels = set([item for sublist in df_labels['targets'].tolist() for item in sublist])\n",
    "\n",
    "print(f\"Number of labels: {len(labels)}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "\n",
    "# one-hot encode labels to columns\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "\n",
    "df_labels = df_labels.join(\n",
    "            pd.DataFrame.sparse.from_spmatrix(\n",
    "                mlb.fit_transform(df_labels.pop('targets')),\n",
    "                index=df_labels.index,\n",
    "                columns=mlb.classes_))\n",
    "df_labels[list(labels)]=df_labels[list(labels)].sparse.to_dense()  # for easy .describe()\n",
    "\n",
    "# show converted data\n",
    "df_labels[['Finding Labels', *list(labels)]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train_val and test sets\n",
    "df_train_val = df_labels[df_labels['Image Index'].isin(train_val_list)]\n",
    "df_test = df_labels[df_labels['Image Index'].isin(test_list)].reset_index()\n",
    "\n",
    "print(f\"Number of train/val images: {len(df_train_val)}\")\n",
    "print(f\"Number of test images: {len(df_test)}\")\n",
    "\n",
    "assert (len(df_train_val) + len(df_test)) == len(df_labels), \"Total number of images does not equal to sum of train/val and test!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-coalition",
   "metadata": {},
   "source": [
    "Take the label *Atelectasis* as pivot, let's build a classifier for it.\n",
    "\n",
    "Settings:\n",
    "1. Consider only PA view images.\n",
    "2. Binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of diseases\n",
    "df_labels[labels].sum().plot(kind=\"bar\", figsize=(10,8))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = 'Atelectasis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution\n",
    "df_labels.describe(include='all')\n",
    "df_labels[disease].hist()\n",
    "print(f\"Fraction of positive class: {len(df_labels[df_labels[disease]==1])/len(df_labels):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 2 notes about train-val split:\n",
    "# 1. make sure the same patient NEVER appears in both sets, to avoid data leakage\n",
    "# 2. Stratify the sampling process to avoid bias, especially for imbalance class\n",
    "# TODO: how to cater for these 2 objectives at the same time?\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.1, stratify=df_train_val[disease], random_state=seed)  # 10% val set, about half the size of test set\n",
    "df_train.reset_index(inplace=True)\n",
    "df_val.reset_index(inplace=True)\n",
    "\n",
    "assert len(df_train) + len(df_val) == len(df_train_val)\n",
    "\n",
    "'''\n",
    "# Prepare train/val and test data\n",
    "def select_images(df):\n",
    "    df = df[df['View Position']=='PA'].reset_index()\n",
    "    return df\n",
    "\n",
    "df_train_pa = select_images(df_train)\n",
    "df_val_pa = select_images(df_val)\n",
    "df_test_pa = select_images(df_test)\n",
    "\n",
    "print(f\"# train images: {df_train_pa.shape[0]}\")\n",
    "print(f\"# val images: {df_val_pa.shape[0]}\")\n",
    "print(f\"# test images: {df_test_pa.shape[0]}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get statistics of training images. \n",
    "# Takes a long time to run as the image set is huge; here we sample it\n",
    "\n",
    "# stack all training images together\n",
    "'''\n",
    "num_channels = 3\n",
    "num_samples = 1000\n",
    "sample_mean = np.zeros(1)\n",
    "sample_var = np.zeros(1)\n",
    "for img_pth in df_train['Image Index'].sample(num_samples):\n",
    "    img_name = os.path.join(DATA_FOLDER, img_pth)\n",
    "    _image = np.array(Image.open(img_name).convert('L'))  # shape: [H,W]\n",
    "    sample_mean += np.mean(_image)\n",
    "    sample_var += np.var(_image)\n",
    "\n",
    "sample_mean = sample_mean/num_samples\n",
    "sample_std = np.sqrt(sample_var/num_samples)\n",
    "print(f\"Mean: {sample_mean}, Std: {sample_std}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or simple use a cached here\n",
    "sample_mean = np.repeat(np.array([129.76628483]), 3)\n",
    "sample_std = np.repeat(np.array([59.70063891]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-general",
   "metadata": {},
   "source": [
    "**Warning: The validation images serve as test set. Do NOT use them for model tuning.**\n",
    "Use leave-out set/CV on training images for tuning instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-distribution",
   "metadata": {},
   "source": [
    "Define our CNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "# avaiable models in PyTorch: [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "\n",
    "# this cell must sit above loader, as image resizing inside transform depends on `input_size`.\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" \n",
    "        Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" \n",
    "        Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" \n",
    "        VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" \n",
    "        Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" \n",
    "        Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "model_name = 'alexnet'\n",
    "num_classes = 2\n",
    "feature_extract = True\n",
    "\n",
    "# Initialize the model for this run\n",
    "model, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model)\n",
    "print(f\"Input image size: {input_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),  # data augmentation\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(sample_mean, sample_std)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((256,256)),  # FIXME: how to cater for different `input_size`?\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(sample_mean, sample_std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "num_neg = sum(df_train[disease] == 0)\n",
    "num_pos = sum(df_train[disease] == 1)\n",
    "assert num_neg + num_pos == len(df_train)\n",
    "print(f\"# of negative/positive cases: {num_neg}:{num_pos}\")\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights\n",
    "class_weight = torch.FloatTensor([(1 / num_neg)*(len(df_train))/2.0, (1 / num_pos)*(len(df_train))/2.0]).to(device)\n",
    "print(f\"Class weight: {class_weight}\")\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # change to CrossEntropyLoss if  multiclass\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight)  # change to CrossEntropyLoss if  multiclass\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-bones",
   "metadata": {},
   "source": [
    "Now we have the images and labels. We can train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "train_data_loader = load_data(df_train, DATA_FOLDER, disease, transform=data_transforms['train'], shuffle=True, batch_size=batch_size)\n",
    "val_data_loader = load_data(df_val, DATA_FOLDER, disease, transform=data_transforms['test'], shuffle=False, batch_size=256)\n",
    "\n",
    "print(f\"Training start. Mode: {device}\")\n",
    "start_time = time.time()\n",
    "model, t_losses, v_losses, v_best_auc, v_roc = train_model(model, train_data_loader, val_data_loader, criterion, optimizer, num_epochs=num_epochs, verbose=False)\n",
    "print(f\"Best ROC achieved on validation set: {v_best_auc:3f}\")\n",
    "print(f'Finished Training. Total time: {(time.time()-start_time)/60} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training and validation loss over epoches\n",
    "plt.figure()\n",
    "plt.plot(t_losses, 'b', label='Training loss')\n",
    "plt.plot(v_losses, 'g', label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot validation roc\n",
    "plt.plot(v_roc, 'g', label='Validation ROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "# load model\n",
    "#model.load_state_dict(torch.load('../models/vgg_1617289457_bestroc_0.742825.pth'))\n",
    "#model.eval()\n",
    "\n",
    "# sometimes GPU goes out of memory. Can clear memory and load the model from disk, lower batch_size, or just use CPU\n",
    "#device = 'cpu'  # comment this out if GPU has sufficient memory\n",
    "\n",
    "test_data_loader = load_data(df_test, DATA_FOLDER, disease, transform=data_transforms['test'], shuffle=False, batch_size=32)\n",
    "test_loss, test_auc, t_prob, t_pred, t_true = eval_model(model.to(device), test_data_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-cover",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "dlh",
   "language": "python",
   "name": "dlh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
