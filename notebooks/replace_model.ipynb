{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "historic-sender",
   "metadata": {},
   "source": [
    "# Starter notebook for NIH Chest Xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-specific setting\n",
    "PROJECT = 'mcsds-dlh'  # CHANGE: billing project name (since the dataset is user-to-pay)\n",
    "DATA_FOLDER = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-albert",
   "metadata": {},
   "source": [
    "## Copy data from GCS (do only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images from GCS. Takes a few minutes.\n",
    "# https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest#gcp_data_access\n",
    "\n",
    "#!gsutil -u {PROJECT} -m -q cp -r gs://gcs-public-data--healthcare-nih-chest-xray/png/*.png {DATA_FOLDER}\n",
    "\n",
    "# Download addition labels\n",
    "# https://pubs.rsna.org/doi/10.1148/radiol.2019191293\n",
    "\n",
    "#!gsutil -u {PROJECT} -m -q cp -r gs://gcs-public-data--healthcare-nih-chest-xray-labels/* {DATA_FOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-mother",
   "metadata": {},
   "source": [
    "# Code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# check if CUDA is available (GPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataset\n",
    "# load train test split\n",
    "with open('train_val_list.txt') as f: \n",
    "    train_val_list = [x.strip() for x in f.readlines()]\n",
    "with open('test_list.txt') as f:\n",
    "    test_list = [x.strip() for x in f.readlines()]\n",
    "\n",
    "# load labels\n",
    "df_labels = pd.read_csv('Data_Entry_2017_v2020.csv')\n",
    "print(f\"Number of images: {len(df_labels)}\")\n",
    "# split the finding (disease) labels, to a list\n",
    "df_labels['targets'] = df_labels['Finding Labels'].str.split(\"|\", expand = False)\n",
    "# look at available labels\n",
    "labels = set([item for sublist in df_labels['targets'].tolist() for item in sublist])\n",
    "\n",
    "print(f\"Number of labels: {len(labels)}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "\n",
    "# one-hot encode labels to columns\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "\n",
    "df_labels = df_labels.join(\n",
    "            pd.DataFrame.sparse.from_spmatrix(\n",
    "                mlb.fit_transform(df_labels.pop('targets')),\n",
    "                index=df_labels.index,\n",
    "                columns=mlb.classes_))\n",
    "df_labels[list(labels)]=df_labels[list(labels)].sparse.to_dense()  # for easy .describe()\n",
    "\n",
    "# show converted data\n",
    "df_labels[['Finding Labels', *list(labels)]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train_val and test sets\n",
    "df_train_val = df_labels[df_labels['Image Index'].isin(train_val_list)]\n",
    "df_test = df_labels[df_labels['Image Index'].isin(test_list)].reset_index()\n",
    "\n",
    "print(f\"Number of train/val images: {len(df_train_val)}\")\n",
    "print(f\"Number of test images: {len(df_test)}\")\n",
    "\n",
    "assert (len(df_train_val) + len(df_test)) == len(df_labels), \"Total number of images does not equal to sum of train/val and test!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-coalition",
   "metadata": {},
   "source": [
    "Take the label *Atelectasis* as pivot, let's build a classifier for it.\n",
    "\n",
    "Settings:\n",
    "1. Consider only PA view images.\n",
    "2. Binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of diseases\n",
    "df_labels[labels].sum().plot(kind=\"bar\", figsize=(10,8))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = 'Atelectasis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution\n",
    "df_labels.describe(include='all')\n",
    "df_labels[disease].hist()\n",
    "print(f\"Fraction of positive class: {len(df_labels[df_labels[disease]==1])/len(df_labels):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 2 notes about train-val split:\n",
    "# 1. make sure the same patient NEVER appears in both sets, to avoid data leakage\n",
    "# 2. Stratify the sampling process to avoid bias, especially for imbalance class\n",
    "# TODO: how to cater for these 2 objectives at the same time?\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.1, stratify=df_train_val[disease], random_state=seed)  # 10% val set, about half the size of test set\n",
    "df_train.reset_index(inplace=True)\n",
    "df_val.reset_index(inplace=True)\n",
    "\n",
    "assert len(df_train) + len(df_val) == len(df_train_val)\n",
    "\n",
    "'''\n",
    "# Prepare train/val and test data\n",
    "def select_images(df):\n",
    "    df = df[df['View Position']=='PA'].reset_index()\n",
    "    return df\n",
    "\n",
    "df_train_pa = select_images(df_train)\n",
    "df_val_pa = select_images(df_val)\n",
    "df_test_pa = select_images(df_test)\n",
    "\n",
    "print(f\"# train images: {df_train_pa.shape[0]}\")\n",
    "print(f\"# val images: {df_val_pa.shape[0]}\")\n",
    "print(f\"# test images: {df_test_pa.shape[0]}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get statistics of training images. \n",
    "# Takes a long time to run as the image set is huge; here we sample it\n",
    "\n",
    "# stack all training images together\n",
    "'''\n",
    "num_channels = 3\n",
    "num_samples = 1000\n",
    "sample_mean = np.zeros(1)\n",
    "sample_var = np.zeros(1)\n",
    "for img_pth in df_train['Image Index'].sample(num_samples):\n",
    "    img_name = os.path.join(DATA_FOLDER, img_pth)\n",
    "    _image = np.array(Image.open(img_name).convert('L'))  # shape: [H,W]\n",
    "    sample_mean += np.mean(_image)\n",
    "    sample_var += np.var(_image)\n",
    "\n",
    "sample_mean = sample_mean/num_samples\n",
    "sample_std = np.sqrt(sample_var/num_samples)\n",
    "print(f\"Mean: {sample_mean}, Std: {sample_std}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or simple use a cached here\n",
    "sample_mean = np.repeat(np.array([129.76628483]), 3)\n",
    "sample_std = np.repeat(np.array([59.70063891]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-momentum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "statistical-general",
   "metadata": {},
   "source": [
    "**Warning: The validation images serve as test set. Do NOT use them for model tuning.**\n",
    "Use leave-out set/CV on training images for tuning instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-bones",
   "metadata": {},
   "source": [
    "Now we have the images and labels. We can train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "# avaiable models in PyTorch: [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "\n",
    "# this cell must sit above loader, as image resizing inside transform depends on `input_size`.\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" \n",
    "        Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" \n",
    "        Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" \n",
    "        VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" \n",
    "        Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" \n",
    "        Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "model_name = 'resnet'\n",
    "num_classes = 2\n",
    "feature_extract = True\n",
    "\n",
    "# Initialize the model for this run\n",
    "model, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model)\n",
    "print(f\"Input image size: {input_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader\n",
    "\n",
    "class NihDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, label, transform=None):\n",
    "        \"\"\"\n",
    "        label: column name of the label of interest, e.g. 'Pleural Effusion'.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.dataframe.loc[idx, 'Image Index'])\n",
    "        # via .getband(), some images are know to have 4 channels.\n",
    "        # Here we may convert them to 1-channel (grayscale) or 3-channel (RGB) depending on the model.\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        target = self.dataframe.loc[idx, disease]\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders to return batch of images\n",
    "def load_data(dataframe, root_dir, label, transform=None, batch_size=32, shuffle=True, num_workers=4):\n",
    "    '''\n",
    "    Data Loader with batch loading and transform.\n",
    "    '''\n",
    "    image_data = NihDataset(dataframe, root_dir, label, transform=transform)\n",
    "    pin = device=='cpu'\n",
    "    loader = torch.utils.data.DataLoader(image_data, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin)\n",
    "    return loader\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),  # data augmentation\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(sample_mean, sample_std)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((256,256)),  # FIXME: how to cater for different `input_size`?\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(sample_mean, sample_std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-distribution",
   "metadata": {},
   "source": [
    "Define our CNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "num_neg = sum(df_train[disease] == 0)\n",
    "num_pos = sum(df_train[disease] == 1)\n",
    "assert num_neg + num_pos == len(df_train)\n",
    "print(f\"# of negative/positive cases: {num_neg}:{num_pos}\")\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights\n",
    "class_weight = torch.FloatTensor([(1 / num_neg)*(len(df_train))/2.0, (1 / num_pos)*(len(df_train))/2.0]).to(device)\n",
    "print(f\"Class weight: {class_weight}\")\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()  # change to CrossEntropyLoss if  multiclass\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight)  # change to CrossEntropyLoss if  multiclass\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, num_epochs=10, verbose=True):\n",
    "    start_time = time.time()\n",
    "    best_val_roc = 0.0\n",
    "    train_losses, val_losses, val_roc = [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"=\"*40)\n",
    "        model.train()\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics every 10 batches\n",
    "            running_loss += loss.item()\n",
    "            if verbose:\n",
    "                if i % 10 == 9:    # print every 10 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "        train_losses.append(running_loss/len(train_data_loader))  # keep trace of train loss in each epoch\n",
    "        print(f'Time elapsed: {(time.time()-start_time)/60.0:.1f} minutes.')\n",
    "        \n",
    "        # validate every epoch\n",
    "        print(\"Validating...\")\n",
    "        val_loss, val_auc, _, _, _ = eval_model(model, valid_loader)\n",
    "        val_roc.append(val_roc)\n",
    "        \n",
    "        # save all models\n",
    "        MODEL_PATH = f'../models/{model_name}_{int(start_time)}_epoch_{epoch}.pth'\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        \n",
    "        # save the best model\n",
    "        if val_auc > best_val_roc:\n",
    "            best_val_roc = val_auc\n",
    "            MODEL_PATH = f'../models/{model_name}_{int(start_time)}_bestroc.pth'\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(\"Model saved!\")\n",
    "            \n",
    "        val_losses.append(val_loss/len(val_data_loader))  # keep trace of validation loss in each epoch\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, num_epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "              \"Validation Loss: {:.3f}.. \".format(val_losses[-1]))\n",
    "    return model, train_losses, val_losses, best_val_roc, val_roc\n",
    "\n",
    "def eval_model(model, loader):\n",
    "    from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
    "    # validate every epoch\n",
    "    loss = 0.0\n",
    "    # Turn off gradients for validation, saves memory and computations\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # empty tensors to hold results\n",
    "        Y_prob, Y_true, Y_pred = [], [], []\n",
    "        for inputs, labels in loader:\n",
    "            probs = model(inputs.to(device)) # prediction probability\n",
    "            labels = labels.type(torch.LongTensor).to(device)  # true labels\n",
    "            _, predicted = torch.max(probs, dim=1)\n",
    "            # stack results\n",
    "            Y_prob.append(probs[:,-1])  # probability of positive class\n",
    "            Y_true.append(labels)\n",
    "            Y_pred.append(predicted)\n",
    "            \n",
    "            loss += criterion(probs, labels)\n",
    "\n",
    "    # convert to numpy\n",
    "    Y_prob = torch.cat(Y_prob).detach().cpu().numpy()\n",
    "    Y_pred = torch.cat(Y_pred).detach().cpu().numpy()\n",
    "    Y_true = torch.cat(Y_true).detach().cpu().numpy()\n",
    "\n",
    "    # TODO: use desired metrics here\n",
    "    print(f\"ROC: {roc_auc_score(Y_true, Y_prob):.3f}\")\n",
    "    fpr, tpr, _ = roc_curve(Y_true, Y_prob)\n",
    "    auc = roc_auc_score(Y_true, Y_prob)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr,tpr,label=f\"Validation, ROCAUC={auc:3f}\")\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "    \n",
    "    print(classification_report(Y_true, Y_pred))\n",
    "    plt.figure()\n",
    "    cm = confusion_matrix(Y_true, Y_pred)  # confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "         \n",
    "    return loss, auc, Y_prob, Y_pred, Y_true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "train_data_loader = load_data(df_train, DATA_FOLDER, disease, transform=data_transforms['train'], shuffle=True, batch_size=batch_size)\n",
    "val_data_loader = load_data(df_val, DATA_FOLDER, disease, transform=data_transforms['test'], shuffle=False, batch_size=256)\n",
    "\n",
    "print(f\"Training start. Mode: {device}\")\n",
    "start_time = time.time()\n",
    "model, t_losses, v_losses, v_best_auc, v_roc = train_model(model, train_data_loader, val_data_loader, num_epochs=num_epochs, verbose=False)\n",
    "print(f\"Best ROC achieved on validation set: {v_best_auc:3f}\")\n",
    "print(f'Finished Training. Total time: {(time.time()-start_time)/60} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training and validation loss over epoches\n",
    "plt.figure()\n",
    "plt.plot(t_losses, 'b', label='Training loss')\n",
    "plt.plot(v_losses, 'g', label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot validation roc\n",
    "plt.plot(v_roc, 'g', label='Validation ROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "# load model\n",
    "#model.load_state_dict(torch.load('../models/vgg_1617289457_bestroc_0.742825.pth'))\n",
    "#model.eval()\n",
    "\n",
    "# sometimes GPU goes out of memory. Can clear memory and load the model from disk, lower batch_size, or just use CPU\n",
    "#device = 'cpu'  # comment this out if GPU has sufficient memory\n",
    "\n",
    "test_data_loader = load_data(df_test, DATA_FOLDER, disease, transform=data_transforms['test'], shuffle=False, batch_size=32)\n",
    "test_loss, test_auc, t_prob, t_pred, t_true = eval_model(model.to(device), test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-cover",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
